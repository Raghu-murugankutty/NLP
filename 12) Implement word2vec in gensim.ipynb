{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement word2vec in gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.0-cp38-cp38-win_amd64.whl (24.0 MB)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\anaconda3\\envs\\kv7006\\lib\\site-packages (from gensim) (6.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\anaconda3\\envs\\kv7006\\lib\\site-packages (from gensim) (1.24.1)\n",
      "Collecting Cython==0.29.32\n",
      "  Downloading Cython-0.29.32-py2.py3-none-any.whl (986 kB)\n",
      "Collecting FuzzyTM>=0.4.0\n",
      "  Downloading FuzzyTM-2.0.5-py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: pandas in c:\\anaconda3\\envs\\kv7006\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (1.2.1)\n",
      "Collecting scipy>=1.7.0\n",
      "  Downloading scipy-1.10.0-cp38-cp38-win_amd64.whl (42.2 MB)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\anaconda3\\envs\\kv7006\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2020.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\anaconda3\\envs\\kv7006\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\anaconda3\\envs\\kv7006\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->FuzzyTM>=0.4.0->gensim) (1.15.0)\n",
      "Collecting pyfume\n",
      "  Downloading pyFUME-0.2.25-py3-none-any.whl (67 kB)\n",
      "Collecting fst-pso\n",
      "  Downloading fst-pso-1.8.1.tar.gz (18 kB)\n",
      "Collecting miniful\n",
      "  Downloading miniful-0.0.6.tar.gz (2.8 kB)\n",
      "Collecting simpful\n",
      "  Downloading simpful-2.9.0-py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: requests in c:\\anaconda3\\envs\\kv7006\\lib\\site-packages (from simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda3\\envs\\kv7006\\lib\\site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda3\\envs\\kv7006\\lib\\site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\envs\\kv7006\\lib\\site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2020.12.5)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\anaconda3\\envs\\kv7006\\lib\\site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.1.1)\n",
      "Building wheels for collected packages: fst-pso, miniful\n",
      "  Building wheel for fst-pso (setup.py): started\n",
      "  Building wheel for fst-pso (setup.py): finished with status 'done'\n",
      "  Created wheel for fst-pso: filename=fst_pso-1.8.1-py3-none-any.whl size=20441 sha256=b4faad93c117032fb12cce09e877f850c155bf81d4d2d1f6257a890136475d99\n",
      "  Stored in directory: c:\\users\\alanj\\appdata\\local\\pip\\cache\\wheels\\6a\\65\\c4\\d27eeee9ba3fc150a0dae150519591103b9e0dbffde3ae77dc\n",
      "  Building wheel for miniful (setup.py): started\n",
      "  Building wheel for miniful (setup.py): finished with status 'done'\n",
      "  Created wheel for miniful: filename=miniful-0.0.6-py3-none-any.whl size=3529 sha256=102d5b92d2a61119173186f4a0384378c95c2e4b136cc5d03880a21cc9536c1b\n",
      "  Stored in directory: c:\\users\\alanj\\appdata\\local\\pip\\cache\\wheels\\ba\\d9\\a0\\ddd93af16d5855dd9bad417623e70948fdac119d1d34fb17c8\n",
      "Successfully built fst-pso miniful\n",
      "Installing collected packages: scipy, miniful, simpful, fst-pso, pyfume, FuzzyTM, Cython, gensim\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.5.2\n",
      "    Uninstalling scipy-1.5.2:\n",
      "      Successfully uninstalled scipy-1.5.2\n",
      "  Attempting uninstall: Cython\n",
      "    Found existing installation: Cython 0.29.33\n",
      "    Uninstalling Cython-0.29.33:\n",
      "      Successfully uninstalled Cython-0.29.33\n",
      "Successfully installed Cython-0.29.32 FuzzyTM-2.0.5 fst-pso-1.8.1 gensim-4.3.0 miniful-0.0.6 pyfume-0.2.25 scipy-1.10.0 simpful-2.9.0\n",
      "Collecting python-Levenshtein\n",
      "  Downloading python_Levenshtein-0.20.9-py3-none-any.whl (9.4 kB)\n",
      "Collecting Levenshtein==0.20.9\n",
      "  Downloading Levenshtein-0.20.9-cp38-cp38-win_amd64.whl (101 kB)\n",
      "Collecting rapidfuzz<3.0.0,>=2.3.0\n",
      "  Downloading rapidfuzz-2.13.7-cp38-cp38-win_amd64.whl (1.0 MB)\n",
      "Installing collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
      "Successfully installed Levenshtein-0.20.9 python-Levenshtein-0.20.9 rapidfuzz-2.13.7\n"
     ]
    }
   ],
   "source": [
    "! pip install gensim\n",
    "! pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and Exploring the Dataset\n",
    "The dataset we are using here is a subset of Amazon reviews from the Cell Phones & Accessories category. The data is stored as a JSON file and can be read using pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to the Dataset: http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Cell_Phones_and_Accessories_5.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Urban Ladder Eisner Low Back Study-Office Comp...</td>\n",
       "      <td>Household</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contrast living Wooden Decorative Box,Painted ...</td>\n",
       "      <td>Household</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IO Crest SY-PCI40010 PCI RAID Host Controller ...</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISAKAA Baby Socks from Just Born to 8 Years- P...</td>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indira Designer Women's Art Mysore Silk Saree ...</td>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                   label\n",
       "0  Urban Ladder Eisner Low Back Study-Office Comp...               Household\n",
       "1  Contrast living Wooden Decorative Box,Painted ...               Household\n",
       "2  IO Crest SY-PCI40010 PCI RAID Host Controller ...             Electronics\n",
       "3  ISAKAA Baby Socks from Just Born to 8 Years- P...  Clothing & Accessories\n",
       "4  Indira Designer Women's Art Mysore Silk Saree ...  Clothing & Accessories"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Ecommerce_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24000, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Preprocessing & Tokenization\n",
    "\n",
    "he first thing to do for any data science task is to clean the data. For NLP, we apply various processing like converting all the words to lower case, trimming spaces, removing punctuations. This is something we will do over here too.\n",
    "\n",
    "Additionally, we can also remove stop words like 'and', 'or', 'is', 'the', 'a', 'an' and convert words to their root forms like 'running' to 'run'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text = df['Text'].apply(gensim.utils.simple_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['urban',\n",
       " 'ladder',\n",
       " 'eisner',\n",
       " 'low',\n",
       " 'back',\n",
       " 'study',\n",
       " 'office',\n",
       " 'computer',\n",
       " 'chair',\n",
       " 'black',\n",
       " 'study',\n",
       " 'in',\n",
       " 'simple',\n",
       " 'the',\n",
       " 'eisner',\n",
       " 'study',\n",
       " 'chair',\n",
       " 'has',\n",
       " 'firm',\n",
       " 'foam',\n",
       " 'cushion',\n",
       " 'which',\n",
       " 'makes',\n",
       " 'long',\n",
       " 'hours',\n",
       " 'at',\n",
       " 'your',\n",
       " 'desk',\n",
       " 'comfortable',\n",
       " 'the',\n",
       " 'flexible',\n",
       " 'meshed',\n",
       " 'back',\n",
       " 'is',\n",
       " 'designed',\n",
       " 'for',\n",
       " 'air',\n",
       " 'circulation',\n",
       " 'and',\n",
       " 'support',\n",
       " 'when',\n",
       " 'you',\n",
       " 'lean',\n",
       " 'back',\n",
       " 'the',\n",
       " 'curved',\n",
       " 'arms',\n",
       " 'provide',\n",
       " 'ergonomic',\n",
       " 'forearm',\n",
       " 'support',\n",
       " 'adjust',\n",
       " 'the',\n",
       " 'height',\n",
       " 'using',\n",
       " 'the',\n",
       " 'gas',\n",
       " 'lift',\n",
       " 'to',\n",
       " 'find',\n",
       " 'that',\n",
       " 'comfortable',\n",
       " 'position',\n",
       " 'and',\n",
       " 'the',\n",
       " 'nylon',\n",
       " 'castors',\n",
       " 'make',\n",
       " 'it',\n",
       " 'easy',\n",
       " 'to',\n",
       " 'move',\n",
       " 'around',\n",
       " 'your',\n",
       " 'space',\n",
       " 'chrome',\n",
       " 'legs',\n",
       " 'refer',\n",
       " 'to',\n",
       " 'the',\n",
       " 'images',\n",
       " 'for',\n",
       " 'dimension',\n",
       " 'details',\n",
       " 'any',\n",
       " 'assembly',\n",
       " 'required',\n",
       " 'will',\n",
       " 'be',\n",
       " 'done',\n",
       " 'by',\n",
       " 'the',\n",
       " 'ul',\n",
       " 'team',\n",
       " 'at',\n",
       " 'the',\n",
       " 'time',\n",
       " 'of',\n",
       " 'delivery',\n",
       " 'indoor',\n",
       " 'use',\n",
       " 'only']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_text.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Word2Vec Model\n",
    "Train the model for reviews. Use a window of size 10 i.e. 10 words before the present word and 10 words ahead. A sentence with at least 2 words should only be considered, configure this using min_count parameter.\n",
    "\n",
    "Workers define how many CPU threads to be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(window = 10, min_count=2, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(processed_text, progress_per=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10339222, 12358775)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(processed_text, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model\n",
    "Save the model so that it can be reused in other applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./word2vec-amazon-cell-accessories-reviews-short.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Similar Words and Similarity between words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chargers', 0.7402549386024475),\n",
       " ('iphones', 0.7249327898025513),\n",
       " ('camcorders', 0.7193127870559692),\n",
       " ('equipment', 0.7189837694168091),\n",
       " ('amps', 0.7177767157554626),\n",
       " ('ipods', 0.7110496759414673),\n",
       " ('consoles', 0.7068403363227844),\n",
       " ('gadgets', 0.6885213851928711),\n",
       " ('jackly', 0.6818183064460754),\n",
       " ('mobiles', 0.6738800406455994)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('electronics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('decorating', 0.6579737663269043),\n",
       " ('beautifying', 0.6225135922431946),\n",
       " ('baskets', 0.6175703406333923),\n",
       " ('organizing', 0.6162499189376831),\n",
       " ('dinning', 0.6087204217910767),\n",
       " ('basket', 0.595137894153595),\n",
       " ('jam', 0.5899482369422913),\n",
       " ('bathrooms', 0.5875928997993469),\n",
       " ('cabins', 0.5875211358070374),\n",
       " ('decorative', 0.5859470367431641)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('household')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5732143"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1='decorating', w2='organizing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26103097"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1='house', w2='dinning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
